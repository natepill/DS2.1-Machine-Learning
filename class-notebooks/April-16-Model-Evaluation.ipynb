{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "pima = pd.read_csv(\"../data/diabetes.csv\")\n",
    "\n",
    "feature_cols = ['Pregnancies','Insulin', 'BMI', 'Age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pima[feature_cols]\n",
    "y = pima['Outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/natepill/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "y_pred = logreg.predict(X_test) # THIS DATA HAS NEVER SEEN ANY TRAINING DATA, BUT THE MODEL HAS BEEN TRAINED USING TRAINING DATA\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[118,  12],\n",
       "       [ 47,  15]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6927083333333334\n",
      "0.5555555555555556\n",
      "0.24193548387096775\n",
      "0.3370786516853933\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.accuracy_score(y_test, y_pred))\n",
    "print(metrics.precision_score(y_test, y_pred))\n",
    "print(metrics.recall_score(y_test, y_pred))\n",
    "print(metrics.f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# When we want to compare two classifers we compare their Accuaracy and F1 scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/natepill/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "y_pred_prob = logreg.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.63247571, 0.36752429],\n",
       "       [0.71643656, 0.28356344],\n",
       "       [0.71104114, 0.28895886],\n",
       "       [0.5858938 , 0.4141062 ],\n",
       "       [0.84103973, 0.15896027],\n",
       "       [0.82934844, 0.17065156],\n",
       "       [0.50110974, 0.49889026],\n",
       "       [0.48658459, 0.51341541],\n",
       "       [0.72321388, 0.27678612],\n",
       "       [0.32810562, 0.67189438],\n",
       "       [0.64244443, 0.35755557],\n",
       "       [0.25912035, 0.74087965],\n",
       "       [0.63949765, 0.36050235],\n",
       "       [0.76987637, 0.23012363],\n",
       "       [0.57345769, 0.42654231],\n",
       "       [0.80896485, 0.19103515],\n",
       "       [0.54236399, 0.45763601],\n",
       "       [0.8809859 , 0.1190141 ],\n",
       "       [0.56071047, 0.43928953],\n",
       "       [0.63038849, 0.36961151],\n",
       "       [0.55812011, 0.44187989],\n",
       "       [0.62388338, 0.37611662],\n",
       "       [0.80183978, 0.19816022],\n",
       "       [0.58322696, 0.41677304],\n",
       "       [0.84451719, 0.15548281],\n",
       "       [0.7468329 , 0.2531671 ],\n",
       "       [0.90256923, 0.09743077],\n",
       "       [0.30366288, 0.69633712],\n",
       "       [0.84641691, 0.15358309],\n",
       "       [0.7802164 , 0.2197836 ],\n",
       "       [0.56905168, 0.43094832],\n",
       "       [0.65783942, 0.34216058],\n",
       "       [0.77603886, 0.22396114],\n",
       "       [0.61926457, 0.38073543],\n",
       "       [0.86657866, 0.13342134],\n",
       "       [0.61209784, 0.38790216],\n",
       "       [0.52950297, 0.47049703],\n",
       "       [0.83795257, 0.16204743],\n",
       "       [0.70451824, 0.29548176],\n",
       "       [0.69081839, 0.30918161],\n",
       "       [0.72700295, 0.27299705],\n",
       "       [0.61183417, 0.38816583],\n",
       "       [0.72646557, 0.27353443],\n",
       "       [0.71118959, 0.28881041],\n",
       "       [0.36528086, 0.63471914],\n",
       "       [0.97634749, 0.02365251],\n",
       "       [0.84179352, 0.15820648],\n",
       "       [0.76981625, 0.23018375],\n",
       "       [0.6515407 , 0.3484593 ],\n",
       "       [0.72419959, 0.27580041],\n",
       "       [0.66735896, 0.33264104],\n",
       "       [0.75119404, 0.24880596],\n",
       "       [0.25510488, 0.74489512],\n",
       "       [0.60998536, 0.39001464],\n",
       "       [0.58374455, 0.41625545],\n",
       "       [0.86424313, 0.13575687],\n",
       "       [0.81104624, 0.18895376],\n",
       "       [0.35222318, 0.64777682],\n",
       "       [0.81077869, 0.18922131],\n",
       "       [0.94314096, 0.05685904],\n",
       "       [0.36008453, 0.63991547],\n",
       "       [0.53363618, 0.46636382],\n",
       "       [0.8749028 , 0.1250972 ],\n",
       "       [0.73042398, 0.26957602],\n",
       "       [0.75080896, 0.24919104],\n",
       "       [0.69429604, 0.30570396],\n",
       "       [0.53623776, 0.46376224],\n",
       "       [0.79036905, 0.20963095],\n",
       "       [0.57152171, 0.42847829],\n",
       "       [0.59237736, 0.40762264],\n",
       "       [0.79830904, 0.20169096],\n",
       "       [0.72972934, 0.27027066],\n",
       "       [0.73744144, 0.26255856],\n",
       "       [0.42761737, 0.57238263],\n",
       "       [0.54532959, 0.45467041],\n",
       "       [0.72283848, 0.27716152],\n",
       "       [0.41998719, 0.58001281],\n",
       "       [0.58400512, 0.41599488],\n",
       "       [0.72723899, 0.27276101],\n",
       "       [0.65900777, 0.34099223],\n",
       "       [0.45373422, 0.54626578],\n",
       "       [0.62069277, 0.37930723],\n",
       "       [0.7007795 , 0.2992205 ],\n",
       "       [0.89940831, 0.10059169],\n",
       "       [0.67127398, 0.32872602],\n",
       "       [0.54898637, 0.45101363],\n",
       "       [0.83963021, 0.16036979],\n",
       "       [0.5103025 , 0.4896975 ],\n",
       "       [0.36769492, 0.63230508],\n",
       "       [0.59261596, 0.40738404],\n",
       "       [0.80205603, 0.19794397],\n",
       "       [0.80301979, 0.19698021],\n",
       "       [0.75536792, 0.24463208],\n",
       "       [0.88852815, 0.11147185],\n",
       "       [0.5841403 , 0.4158597 ],\n",
       "       [0.78438144, 0.21561856],\n",
       "       [0.45875471, 0.54124529],\n",
       "       [0.51196398, 0.48803602],\n",
       "       [0.35347233, 0.64652767],\n",
       "       [0.66059342, 0.33940658],\n",
       "       [0.45736573, 0.54263427],\n",
       "       [0.83786176, 0.16213824],\n",
       "       [0.6221259 , 0.3778741 ],\n",
       "       [0.88688713, 0.11311287],\n",
       "       [0.65218013, 0.34781987],\n",
       "       [0.65957216, 0.34042784],\n",
       "       [0.8209015 , 0.1790985 ],\n",
       "       [0.78675188, 0.21324812],\n",
       "       [0.85289054, 0.14710946],\n",
       "       [0.76985898, 0.23014102],\n",
       "       [0.81595408, 0.18404592],\n",
       "       [0.47775351, 0.52224649],\n",
       "       [0.52900634, 0.47099366],\n",
       "       [0.71115752, 0.28884248],\n",
       "       [0.50674921, 0.49325079],\n",
       "       [0.58255527, 0.41744473],\n",
       "       [0.77084992, 0.22915008],\n",
       "       [0.72977089, 0.27022911],\n",
       "       [0.80756076, 0.19243924],\n",
       "       [0.2501287 , 0.7498713 ],\n",
       "       [0.53499907, 0.46500093],\n",
       "       [0.3354546 , 0.6645454 ],\n",
       "       [0.57901401, 0.42098599],\n",
       "       [0.46435966, 0.53564034],\n",
       "       [0.83965298, 0.16034702],\n",
       "       [0.8564314 , 0.1435686 ],\n",
       "       [0.61857574, 0.38142426],\n",
       "       [0.66172686, 0.33827314],\n",
       "       [0.6369935 , 0.3630065 ],\n",
       "       [0.87157469, 0.12842531],\n",
       "       [0.71666307, 0.28333693],\n",
       "       [0.95994442, 0.04005558],\n",
       "       [0.81518861, 0.18481139],\n",
       "       [0.33283053, 0.66716947],\n",
       "       [0.53647126, 0.46352874],\n",
       "       [0.51284318, 0.48715682],\n",
       "       [0.80089206, 0.19910794],\n",
       "       [0.54138349, 0.45861651],\n",
       "       [0.76783279, 0.23216721],\n",
       "       [0.81630733, 0.18369267],\n",
       "       [0.73608006, 0.26391994],\n",
       "       [0.62507031, 0.37492969],\n",
       "       [0.87083494, 0.12916506],\n",
       "       [0.58586087, 0.41413913],\n",
       "       [0.57539142, 0.42460858],\n",
       "       [0.86167809, 0.13832191],\n",
       "       [0.79218306, 0.20781694],\n",
       "       [0.70522301, 0.29477699],\n",
       "       [0.84174901, 0.15825099],\n",
       "       [0.63983766, 0.36016234],\n",
       "       [0.76258551, 0.23741449],\n",
       "       [0.56649311, 0.43350689],\n",
       "       [0.79380119, 0.20619881],\n",
       "       [0.76837662, 0.23162338],\n",
       "       [0.38888459, 0.61111541],\n",
       "       [0.80268991, 0.19731009],\n",
       "       [0.19928502, 0.80071498],\n",
       "       [0.82191509, 0.17808491],\n",
       "       [0.63511265, 0.36488735],\n",
       "       [0.21381357, 0.78618643],\n",
       "       [0.55919386, 0.44080614],\n",
       "       [0.63440346, 0.36559654],\n",
       "       [0.88239862, 0.11760138],\n",
       "       [0.77156675, 0.22843325],\n",
       "       [0.52134931, 0.47865069],\n",
       "       [0.78679475, 0.21320525],\n",
       "       [0.48501479, 0.51498521],\n",
       "       [0.83877506, 0.16122494],\n",
       "       [0.76259881, 0.23740119],\n",
       "       [0.70625609, 0.29374391],\n",
       "       [0.83329952, 0.16670048],\n",
       "       [0.51283474, 0.48716526],\n",
       "       [0.70030106, 0.29969894],\n",
       "       [0.55348957, 0.44651043],\n",
       "       [0.49830098, 0.50169902],\n",
       "       [0.70753494, 0.29246506],\n",
       "       [0.38263772, 0.61736228],\n",
       "       [0.58406005, 0.41593995],\n",
       "       [0.74179055, 0.25820945],\n",
       "       [0.8258032 , 0.1741968 ],\n",
       "       [0.66480459, 0.33519541],\n",
       "       [0.30393175, 0.69606825],\n",
       "       [0.67545632, 0.32454368],\n",
       "       [0.64269574, 0.35730426],\n",
       "       [0.7663053 , 0.2336947 ],\n",
       "       [0.76261476, 0.23738524],\n",
       "       [0.61590682, 0.38409318],\n",
       "       [0.75308588, 0.24691412],\n",
       "       [0.72045448, 0.27954552],\n",
       "       [0.81498826, 0.18501174],\n",
       "       [0.7377638 , 0.2622362 ],\n",
       "       [0.72143074, 0.27856926]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_pred_prob[:, 1], bins=8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3576388888888889"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = y_train.value_counts()[1] / len(y_train) # why is this the threshold?\n",
    "threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192\n",
      "81\n",
      "111\n"
     ]
    }
   ],
   "source": [
    "num_of_0 = 0\n",
    "num_of_1 = 0\n",
    "\n",
    "for arr in y_pred_prob:\n",
    "    if arr[1] >= threshold:\n",
    "        num_of_0 += 1\n",
    "    else:\n",
    "        num_of_1 += 1\n",
    "        \n",
    "print(len(y_pred))\n",
    "print(num_of_0)\n",
    "print(num_of_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With reevaluation of confusion matrix with the optimal threshold edit, we get a slightly worse accuracy, but a MUCH HIGHER F1 score, making the mode with the optimal threshold the better model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
